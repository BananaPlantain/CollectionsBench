{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMPTY = '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_params(df):\n",
    "    \n",
    "    params = df.params\n",
    "    if 'impl' in params:\n",
    "        df['impl'] = params['impl']\n",
    "    else:\n",
    "        df['impl'] = df['benchmark'].split('.')[-2]\n",
    "    \n",
    "    if 'payloadType' in params:\n",
    "        df['payloadType'] = params['payloadType']\n",
    "    else:\n",
    "        df['payloadType'] = EMPTY\n",
    "        \n",
    "    if 'workload' in params:\n",
    "        df['workload'] = params['workload']\n",
    "    else:\n",
    "        df['workload'] = EMPTY\n",
    "    \n",
    "    df['size'] = params['size']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Benchmark Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "bmatch = re.compile(r\"^de.heidelberg.pvs.container_bench.benchmarks\\.([a-z0-9.]+)\\.([A-Z][A-Za-z0-9]+)\\.([a-zA-Z0-9_.]+)$\")\n",
    "\n",
    "def normalize_benchmark(df):\n",
    "    fullbench = df.benchmark\n",
    "    match = bmatch.match(fullbench)\n",
    "    df['bench_id'] = match[1]\n",
    "    df['class'] = match[2]\n",
    "    df['method'] = match[3]\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Aggregate Results\n",
    "\n",
    "#### JSON Structure\n",
    "\n",
    "##### PrimaryMetric\n",
    "\n",
    "- score\n",
    "- scoreError\n",
    "- scoreConfidence\n",
    "- scorePercentiles\n",
    "- scoreUnit\n",
    "- rawDataHistogram\n",
    "\n",
    "##### Secondary Metric\n",
    "\n",
    "- Basically the percentiles (have to explore more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def aggregate_results_from_sample(df): \n",
    "    df['mean'] = df.primaryMetric['score']\n",
    "    df['error'] = df.primaryMetric['scoreError']\n",
    "    df['confidence'] = df.primaryMetric['scoreConfidence']\n",
    "    df['median'] = df.primaryMetric['scorePercentiles']['50.0']\n",
    "    df['min'] = df.primaryMetric['scorePercentiles']['0.0']\n",
    "    df['max'] = df.primaryMetric['scorePercentiles']['100.0']\n",
    "    df['scorePercentiles'] = df.primaryMetric['scorePercentiles']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_results_from_ss(df):\n",
    "    raw = np.array(df['rawData']).flatten()\n",
    "    # Validate the array\n",
    "    expect = df[\"measurementIterations\"]\n",
    "    assert (raw.shape[0] == expect)\n",
    "    \n",
    "    # Mean and standard deviation\n",
    "    df['mean'] = np.mean(raw)\n",
    "    df['error'] = stats.sem(raw, ddof=1)\n",
    "    df['median'] = np.median(raw)\n",
    "    df['min'] = np.min(raw)\n",
    "    df['max'] = np.max(raw)\n",
    "    df['scorePercentiles'] = np.percentile(raw, q=[.0, .5, .9, .95, .99, 1.])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save into Disk \n",
    "\n",
    "Remove very long columns first \n",
    "- primaryMetric\n",
    "- secondaryMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute all Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['20180822_intsets_100_100k.json',\n",
    "    '20180828_intsets_1M.json',\n",
    "    '20180822_sets_100_100k.json',\n",
    "    '20180827_sets_1M.json']\n",
    "\n",
    "files = ['20180701_singleoperations_lists.json', \n",
    "    '20180712_singleoperations_maps.json', \n",
    "    '20180713_singleoperations_sets.json', \n",
    "    '20180715_wordcount_sample.json', \n",
    "    '20180714_singleoperations_intmaps.json', \n",
    "    '20180714_singleoperations_intsets.json']\n",
    "\n",
    "files = ['20180808_concurrency_lists.json',\n",
    "         '20180808_concurrency_sets.json',\n",
    "         '20180808_concurrency_maps']\n",
    "\n",
    "files = ['20180808_concurrency_maps.json']\n",
    "\n",
    "files = ['20180713_singleoperations_hppcmaps.json', \n",
    "        '20180713_singleoperations_hppcsets.json',\n",
    "        '20180827_sets_1M.json',\n",
    "        '20180828_intsets_1M.json']\n",
    "\n",
    "files = ['20180828_intsets_1M.json']\n",
    "\n",
    "folder = '../results/EMSE/'\n",
    "output_folder = '../results/EMSE/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file 20180828_intsets_1M.json\n",
      "Error while parsing the file. ERROR Trailing data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    print('Reading file %s' % f)\n",
    "    output = f.replace('.json', '_aggregated.csv')\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_json(os.path.join(folder, f))\n",
    "        \n",
    "    \n",
    "    except ValueError as e:\n",
    "        print('Error while parsing the file. ERROR %s' % e)\n",
    "        continue\n",
    "    \n",
    "    df = df.apply(normalize_params, axis=1)\n",
    "    df = df.apply(normalize_benchmark, axis=1)\n",
    "    df = df.apply(aggregate_results_from_sample, axis=1)\n",
    "    \n",
    "    del df['primaryMetric']\n",
    "    del df['secondaryMetrics']\n",
    "    \n",
    "    print('Saving file %s' % output)\n",
    "    df.to_csv(os.path.join(output_folder, output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append all Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggregated_files = [\n",
    "    '20180701_singleoperations_lists_aggregated',\n",
    "    '20180712_singleoperations_maps_aggregated',\n",
    "    '20180713_singleoperations_hppcmaps_aggregated',\n",
    "    '20180713_singleoperations_hppcsets_aggregated',\n",
    "    '20180713_singleoperations_sets_aggregated',\n",
    "    '20180714_singleoperations_intmaps_aggregated',\n",
    "    '20180714_singleoperations_intsets_aggregated',\n",
    "    '20180715_wordcount_sample_aggregated',\n",
    "    '20180808_concurrency_lists_aggregated',\n",
    "    '20180808_concurrency_maps_aggregated',\n",
    "    '20180808_concurrency_sets_aggregated',\n",
    "    # 20180912_intsets_1M_aggregated,\n",
    "    '20180822_intsets_100_100k_aggregated',\n",
    "    '20180822_sets_100_100k_aggregated',\n",
    "    '20180827_sets_1M_aggregated',\n",
    "]\n",
    "\n",
    "aggregated_df = pd.DataFrame()\n",
    "\n",
    "for f in aggregated_files:\n",
    "    \n",
    "    tmp = pd.read_csv(os.path.join(folder, f + '.csv'))\n",
    "    aggregated_df = aggregated_df.append(tmp)\n",
    "\n",
    "len(aggregated_df)\n",
    "aggregated_df.to_csv(os.path.join(folder, 'aggregated_results.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
